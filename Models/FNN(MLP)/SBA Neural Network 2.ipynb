{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d27cc2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aiden\\AppData\\Local\\Temp\\ipykernel_11520\\939327999.py:42: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\aiden\\AppData\\Local\\Temp\\ipykernel_11520\\939327999.py:42: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\aiden\\AppData\\Local\\Temp\\ipykernel_11520\\939327999.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\aiden\\AppData\\Local\\Temp\\ipykernel_11520\\939327999.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\aiden\\AppData\\Local\\Temp\\ipykernel_11520\\939327999.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imblearn\n",
    "import tensorflow as tf\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "def preprocessing():\n",
    "    # Removes the dollar signs and commas\n",
    "    def custom_dollar_converter(dollar_str):\n",
    "        if '#' in dollar_str:\n",
    "            return np.nan\n",
    "        else:\n",
    "            dollar_str = dollar_str.replace('$', '').replace(',', '')\n",
    "            return float(dollar_str)\n",
    "    \n",
    "    # Determines whether a business is a franchise or not\n",
    "    # If the value is 0 or 1, the business is not a franchise\n",
    "    def custom_franchise_converter(franchise_str):\n",
    "        if franchise_str.strip() == '0' or franchise_str.strip() == '1':\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    \n",
    "    # Trims zip codes to the first two numbers\n",
    "    def zip_trimmer(zip_str):\n",
    "        return zip_str[:2]\n",
    "    \n",
    "    # reads in data, using the custom converters\n",
    "    bank_converters = {\n",
    "        'DisbursementGross': custom_dollar_converter,\n",
    "        'BalanceGross': custom_dollar_converter,\n",
    "        'ChgOffPrinGr': custom_dollar_converter,\n",
    "        'GrAppv': custom_dollar_converter,\n",
    "        'SBA_Appv': custom_dollar_converter,\n",
    "        'FranchiseCode': custom_franchise_converter,\n",
    "        'Zip': zip_trimmer,\n",
    "    }\n",
    "    \n",
    "    bank_parse_dates = [ 'ApprovalDate', 'ChgOffDate', 'DisbursementDate' ]\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        'SBAnational.csv',\n",
    "        converters=bank_converters,\n",
    "        parse_dates=bank_parse_dates,\n",
    "        date_parser=pd.to_datetime,\n",
    "    )\n",
    "\n",
    "    # drops unnecessary columns\n",
    "    drop_columns = [\n",
    "        'Name', 'City', 'ChgOffDate', 'DisbursementDate',\n",
    "        'LoanNr_ChkDgt', 'Bank', 'NAICS',\n",
    "        'CreateJob', 'RetainedJob', 'ChgOffPrinGr',\n",
    "        'RevLineCr', 'LowDoc',\n",
    "    ]\n",
    "    working_df = df.drop(columns=drop_columns)\n",
    "    \n",
    "    # removes all null values\n",
    "    working_df = working_df.dropna()\n",
    "    \n",
    "    \n",
    "    # label encode MIS_Status\n",
    "    mis_label_encoder = LabelEncoder()\n",
    "    mis_encoded = mis_label_encoder.fit_transform(working_df['MIS_Status'])\n",
    "    working_df['MIS_Status'] = mis_encoded\n",
    "    \n",
    "    \n",
    "    # makes the NewExist variable more intuitive\n",
    "    # a value of 1 means the business is new\n",
    "    # a value of 0 means the business is not new\n",
    "    working_df['NewExist'] = working_df['NewExist'].replace({ 2:1, 1:0 })\n",
    "    # one hot encoding NewExist\n",
    "    new_exist_true = working_df['NewExist'] == 1\n",
    "    new_exist_false = working_df['NewExist'] == 0\n",
    "    working_df['NewExistTrue'] = new_exist_true\n",
    "    working_df['NewExistFalse'] = new_exist_false\n",
    "    working_df = working_df.drop(columns=['NewExist'])\n",
    "    \n",
    "\n",
    "    # handling datetime information\n",
    "    approval_date_months = working_df['ApprovalDate'].dt.month\n",
    "    approval_date_days = working_df['ApprovalDate'].dt.day\n",
    "    working_df['ApprovalMonth'] = approval_date_months\n",
    "    working_df['ApprovalDay'] = approval_date_days\n",
    "    working_df = working_df.drop(columns=['ApprovalDate'])\n",
    "\n",
    "    approval_years = []\n",
    "    for date in working_df['ApprovalFY']:\n",
    "        if date == '1976A':\n",
    "            approval_years.append(1976)\n",
    "        else:\n",
    "            approval_years.append(int(date))\n",
    "\n",
    "    working_df['ApprovalFY'] = np.array(approval_years).astype(np.int64)\n",
    "    \n",
    "    \n",
    "    # label encoding state information\n",
    "    state_label_encoder = LabelEncoder()\n",
    "    state_encoded = state_label_encoder.fit_transform(working_df['State'])\n",
    "    bank_state_encoded = state_label_encoder.fit_transform(working_df['BankState'])\n",
    "    working_df['State'] = state_encoded\n",
    "    working_df['BankState'] = bank_state_encoded\n",
    "    \n",
    "    \n",
    "    # converting zip information to the right datatype\n",
    "    working_df['Zip'] = pd.to_numeric(working_df['Zip'])\n",
    "    \n",
    "    \n",
    "    # separate data by features and target\n",
    "    X = working_df.drop(columns=['MIS_Status'])\n",
    "    y = working_df['MIS_Status']\n",
    "    # separate the testing data from the training data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    \n",
    "    # balancing the training data based on MIS_Status\n",
    "    sampler = RandomOverSampler(sampling_strategy='minority')\n",
    "    df_without_status, df_with_status = X_train, y_train\n",
    "    df_without_status_rebalanced, df_with_status_rebalanced = sampler.fit_resample(\n",
    "        df_without_status, df_with_status\n",
    "    )\n",
    "    X_train, y_train = df_without_status_rebalanced, df_with_status_rebalanced\n",
    "    \n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8081b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7082a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cade5c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Layer\n",
    "model.add(tf.keras.layers.Dense(units=300, activation='relu'))\n",
    "\n",
    "# Second Hidden Layer\n",
    "model.add(tf.keras.layers.Dense(units=200, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(units=100, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(units=50, activation='relu'))\n",
    "#Output Layer\n",
    "model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3e41671",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "acc67591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "23617/23617 [==============================] - 45s 2ms/step - loss: 0.3230 - accuracy: 0.8650\n",
      "Epoch 2/60\n",
      "23617/23617 [==============================] - 46s 2ms/step - loss: 0.2675 - accuracy: 0.8908\n",
      "Epoch 3/60\n",
      "23617/23617 [==============================] - 41s 2ms/step - loss: 0.2499 - accuracy: 0.8986\n",
      "Epoch 4/60\n",
      "23617/23617 [==============================] - 39s 2ms/step - loss: 0.2374 - accuracy: 0.9042\n",
      "Epoch 5/60\n",
      "23617/23617 [==============================] - 37s 2ms/step - loss: 0.2262 - accuracy: 0.9092\n",
      "Epoch 6/60\n",
      "23617/23617 [==============================] - 37s 2ms/step - loss: 0.2181 - accuracy: 0.9127\n",
      "Epoch 7/60\n",
      "23617/23617 [==============================] - 37s 2ms/step - loss: 0.2121 - accuracy: 0.9154\n",
      "Epoch 8/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.2073 - accuracy: 0.9176\n",
      "Epoch 9/60\n",
      "23617/23617 [==============================] - 37s 2ms/step - loss: 0.2035 - accuracy: 0.9192\n",
      "Epoch 10/60\n",
      "23617/23617 [==============================] - 37s 2ms/step - loss: 0.1999 - accuracy: 0.9210\n",
      "Epoch 11/60\n",
      "23617/23617 [==============================] - 37s 2ms/step - loss: 0.1968 - accuracy: 0.9226\n",
      "Epoch 12/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1944 - accuracy: 0.9233\n",
      "Epoch 13/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1916 - accuracy: 0.9249\n",
      "Epoch 14/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1897 - accuracy: 0.9258\n",
      "Epoch 15/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1870 - accuracy: 0.9267\n",
      "Epoch 16/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1855 - accuracy: 0.9275\n",
      "Epoch 17/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1841 - accuracy: 0.9283\n",
      "Epoch 18/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1812 - accuracy: 0.9294\n",
      "Epoch 19/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.2377 - accuracy: 0.9298\n",
      "Epoch 20/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1778 - accuracy: 0.9307\n",
      "Epoch 21/60\n",
      "23617/23617 [==============================] - 39s 2ms/step - loss: 0.1770 - accuracy: 0.9312\n",
      "Epoch 22/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1788 - accuracy: 0.9318\n",
      "Epoch 23/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1740 - accuracy: 0.9327\n",
      "Epoch 24/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1728 - accuracy: 0.9331\n",
      "Epoch 25/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1712 - accuracy: 0.9338\n",
      "Epoch 26/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1699 - accuracy: 0.9342\n",
      "Epoch 27/60\n",
      "23617/23617 [==============================] - 37s 2ms/step - loss: 0.1683 - accuracy: 0.9350\n",
      "Epoch 28/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1700 - accuracy: 0.9352\n",
      "Epoch 29/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.4549 - accuracy: 0.9353\n",
      "Epoch 30/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1654 - accuracy: 0.9363\n",
      "Epoch 31/60\n",
      "23617/23617 [==============================] - 39s 2ms/step - loss: 0.1647 - accuracy: 0.9366\n",
      "Epoch 32/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1636 - accuracy: 0.9370\n",
      "Epoch 33/60\n",
      "23617/23617 [==============================] - 39s 2ms/step - loss: 3.9191 - accuracy: 0.9361\n",
      "Epoch 34/60\n",
      "23617/23617 [==============================] - 39s 2ms/step - loss: 0.1629 - accuracy: 0.9375\n",
      "Epoch 35/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1608 - accuracy: 0.9381\n",
      "Epoch 36/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1605 - accuracy: 0.9386\n",
      "Epoch 37/60\n",
      "23617/23617 [==============================] - 37s 2ms/step - loss: 0.1596 - accuracy: 0.9391\n",
      "Epoch 38/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1582 - accuracy: 0.9394\n",
      "Epoch 39/60\n",
      "23617/23617 [==============================] - 37s 2ms/step - loss: 0.1602 - accuracy: 0.9395\n",
      "Epoch 40/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1567 - accuracy: 0.9399\n",
      "Epoch 41/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.6811 - accuracy: 0.9389\n",
      "Epoch 42/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1574 - accuracy: 0.9400\n",
      "Epoch 43/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1561 - accuracy: 0.9405\n",
      "Epoch 44/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.6071 - accuracy: 0.9393\n",
      "Epoch 45/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1549 - accuracy: 0.9415\n",
      "Epoch 46/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1546 - accuracy: 0.9416\n",
      "Epoch 47/60\n",
      "23617/23617 [==============================] - 39s 2ms/step - loss: 0.1534 - accuracy: 0.9419\n",
      "Epoch 48/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1527 - accuracy: 0.9425\n",
      "Epoch 49/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1520 - accuracy: 0.9427\n",
      "Epoch 50/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 5.7151 - accuracy: 0.9403\n",
      "Epoch 51/60\n",
      "23617/23617 [==============================] - 39s 2ms/step - loss: 0.1631 - accuracy: 0.9406\n",
      "Epoch 52/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1532 - accuracy: 0.9425\n",
      "Epoch 53/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1512 - accuracy: 0.9431\n",
      "Epoch 54/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1511 - accuracy: 0.9434\n",
      "Epoch 55/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1499 - accuracy: 0.9435\n",
      "Epoch 56/60\n",
      "23617/23617 [==============================] - 39s 2ms/step - loss: 0.2591 - accuracy: 0.9411\n",
      "Epoch 57/60\n",
      "23617/23617 [==============================] - 39s 2ms/step - loss: 0.1560 - accuracy: 0.9429\n",
      "Epoch 58/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1488 - accuracy: 0.9441\n",
      "Epoch 59/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1492 - accuracy: 0.9444\n",
      "Epoch 60/60\n",
      "23617/23617 [==============================] - 38s 2ms/step - loss: 0.1483 - accuracy: 0.9446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2ce5d57b350>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=50, epochs=60, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e85ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
